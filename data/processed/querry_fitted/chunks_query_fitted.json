[
  {
    "chunk_id": 0,
    "text": "Our subject today is Fermi’s golden rule. This concerns the study of transitions, particularly transitions from a discrete initial state into a continuum of final states. While transitions between two discrete states are relatively straightforward to analyze, transitions into a continuum require integrating over a range of final states, which makes the problem more subtle and interesting.\n\nWe will consider two main types of perturbations. The first is a constant perturbation, where the Hamiltonian is written as H = H0 + V, with V turning on at time zero and remaining constant thereafter. Although this is treated using time-dependent perturbation theory, the time dependence arises only from the sudden switching-on of the perturbation. The second case is a harmonic perturbation, where the Hamiltonian includes a term oscillating sinusoidally in time. Today we will focus primarily on the constant perturbation case, which is essential for understanding phenomena such as autoionization.\n\nBecause transitions into a continuum are central to this discussion, we must first understand how to describe continuum states. A free particle has a continuous spectrum of momentum values, and so the number of states cannot be counted directly. To handle this, we introduce a mathematical device: we imagine placing the system inside a very large box of length L. This discretizes the momentum spectrum, allowing us to count states, and at the end of the calculation the dependence on L disappears.\n\nWith periodic boundary conditions imposed on the box, the allowed momentum components are quantized. The number of states within a small volume of momentum space can then be computed, leading to an expression for the density of states. By relating momentum to energy, we obtain the density of states per unit energy, which will later appear explicitly in the transition rate.\n\nWe now turn to transitions caused by a constant perturbation. The perturbation V is time independent and turns on at time zero. We consider a transition from an initial state i to a final state f. Using first-order time-dependent perturbation theory, the transition amplitude is given by an integral over time involving the matrix element of the perturbation and a phase factor determined by the energy difference between the states.\n\nEvaluating this integral yields a transition probability that oscillates in time. When the energy of the final state differs significantly from that of the initial state, the transition probability is suppressed. This reflects the fact that a constant perturbation does not efficiently supply energy to drive transitions that change the energy by a large amount.\n\nA particularly important case arises when the final state has the same energy as the initial state. In this limit, the transition probability grows quadratically with time, but this behavior cannot persist indefinitely because perturbation theory breaks down once the probability becomes appreciable. This signals the need to consider transitions into a continuum of states, rather than a single final state.",
    "num_tokens": 478
  },
  {
    "chunk_id": 1,
    "text": "We now consider transitions from a discrete initial state into a continuum of final states. The total transition probability is obtained by summing, or equivalently integrating, over all final states in the continuum. This introduces the density of states into the calculation. The resulting expression involves an integral over energy of a function containing a sinc-squared term, which becomes sharply peaked around energy conservation as the interaction time becomes large.\n\nAs the interaction time increases, the dominant contribution to the integral comes from final states whose energies are very close to that of the initial state. This reflects energy conservation in the long-time limit, consistent with the energy–time uncertainty principle. In this limit, the transition probability becomes proportional to time.\n\nDividing the transition probability by time yields a constant transition rate. This rate is given by the famous result known as Fermi’s golden rule. It states that the transition rate from an initial state into a continuum of final states is equal to two pi over h-bar times the squared magnitude of the transition matrix element, multiplied by the density of states evaluated at the initial energy.\n\nThis result has the correct physical dimensions and applies provided the perturbation is sufficiently weak and the interaction time is long compared to microscopic timescales, but not so long that perturbation theory fails. Fermi’s golden rule provides a powerful and widely applicable tool for computing transition rates in quantum mechanics.\n\nAs an application, consider autoionization, also known as Auger transitions. In a helium atom, two electrons interact via Coulomb repulsion. Certain excited states lie energetically within a continuum of states where one electron is bound and the other is free. These discrete states are unstable because they can decay into the continuum through electron–electron interactions.\n\nIn such a process, one electron transitions to a lower bound state while the other is ejected into the continuum, carrying away the excess energy. This decay is nonradiative and is often much more probable than radiative transitions. Fermi’s golden rule provides a natural framework for understanding and calculating the rate of such processes.\n\nThis concludes our qualitative discussion of Fermi’s golden rule and its application to transitions into the continuum. We will explore further applications and refinements in subsequent lectures.",
    "num_tokens": 373
  },
  {
    "chunk_id": 2,
    "text": "Today we turn to harmonic perturbations. Previously, we derived Fermi’s golden rule for constant perturbations and studied transitions from discrete states into a continuum. We now consider the case in which the perturbation oscillates in time with a definite frequency. Although this introduces new features, the final form of Fermi’s golden rule will look very similar to what we obtained before.\n\nA particularly important application of this formalism is the ionization of hydrogen. A hydrogen atom initially in its ground state can absorb energy from an electromagnetic wave and eject its electron. Our goal is to compute the ionization rate and to understand the assumptions under which the calculation is valid.\n\nWe describe harmonic perturbations by writing the Hamiltonian as H = H0 + ΔH(t), where ΔH(t) is proportional to cos(ωt) for a finite duration of time. By convention, this perturbation is written as 2H′ cos(ωt). The factor of two is chosen so that, when the cosine is expressed in terms of exponentials, the resulting formulas take a clean and symmetric form.\n\nWe consider transitions from an initial state to a final state using time-dependent perturbation theory. The system is assumed to start in a definite initial state at time zero, and the transition amplitude to a final state is computed to first order in the perturbation. The expression for this amplitude involves time integrals of oscillatory exponentials, which can be evaluated explicitly.\n\nThese integrals naturally separate into two terms. One corresponds to the case in which the system absorbs energy from the perturbation, increasing its energy by ℏω. The other corresponds to stimulated emission, in which the system transitions to a lower-energy state while transferring energy ℏω back to the perturbation. Both processes are described within the same formal framework.\n\nWhen the transition probability is summed over a continuum of final states, the result simplifies dramatically. As in the case of constant perturbations, the dominant contribution comes from final states whose energies satisfy the appropriate energy-conservation condition. In the long-time limit, the transition probability grows linearly in time, allowing us to define a transition rate.\n\nThis leads again to Fermi’s golden rule. For harmonic perturbations, the transition rate is proportional to the square of the matrix element of the perturbation and the density of states evaluated at the final energy, which differs from the initial energy by ℏω. The same rule applies to both absorption and stimulated emission, with the sign of the energy shift distinguishing the two processes.",
    "num_tokens": 410
  },
  {
    "chunk_id": 3,
    "text": "We now apply this framework to the ionization of hydrogen. We imagine a hydrogen atom in its ground state exposed to an oscillating electric field. If the photon energy is sufficiently large, the electron can be ejected from the atom. The kinetic energy of the emitted electron is equal to the photon energy minus the binding energy of the ground state.\n\nBefore performing the calculation, it is essential to establish the conditions under which our approximations are valid. The wavelength of the incident radiation must be much larger than the size of the atom so that the electric field can be treated as spatially uniform across the atom. This places an upper bound on the photon energy. At the same time, the photon energy must be large enough to overcome the binding energy of the electron and to ensure that the emitted electron can be treated as a free particle.\n\nWithin this regime, the perturbation Hamiltonian is given by the coupling of the electron to the electric field. By choosing coordinates so that the electric field is aligned along a fixed axis, the perturbation can be written in a simple form proportional to the electron’s position. The initial state is the hydrogen ground-state wave function, and the final state is taken to be a plane wave representing the ejected electron.\n\nTo compute the transition rate, we must evaluate the matrix element of the perturbation between the initial and final states. This requires integrating over all space and carefully accounting for the angular dependence of the electric field, the electron momentum, and the position vector. Several angles enter the problem, but symmetry considerations allow many terms to vanish upon integration.\n\nAfter simplifying the angular integrals, the remaining radial and angular integrals can be evaluated explicitly. The final expression for the matrix element has a simple dependence on the electron momentum and the angle between the emitted electron and the electric field. Importantly, the result has the correct physical dimensions and behaves sensibly in the relevant limits.\n\nWith the matrix element in hand, Fermi’s golden rule can be applied directly. The integration over final states is straightforward because the golden rule has already accounted for the continuum. The resulting ionization rate depends on the intensity of the electric field, the photon energy, and the density of final states.\n\nThis completes the calculation of the ionization rate of hydrogen using harmonic perturbations and Fermi’s golden rule. The example illustrates both the power of the formalism and the importance of carefully analyzing the assumptions underlying the approximations. Further applications will continue to build on these ideas.",
    "num_tokens": 432
  },
  {
    "chunk_id": 4,
    "text": "Today we continue our discussion of atom–light interactions and complete the analysis of hydrogen ionization. We will also introduce Einstein’s arguments for absorption, stimulated emission, and spontaneous emission, which connect quantum transitions with thermal radiation.\n\nWe begin by recalling the final result for the ionization rate of hydrogen. The process involves a hydrogen atom initially in its ground state interacting with an electromagnetic wave. The electron is ejected and treated as a plane wave, provided the photon energy is sufficiently large compared to the binding energy, but not so large that spatial variations of the field across the atom become important.\n\nThe main technical challenge in this calculation was the evaluation of the transition matrix element. This required careful treatment of the spatial integral and the angular dependence, particularly the angle between the polarization of the electric field and the momentum of the emitted electron. The resulting expression shows that electron emission is strongly directional, favoring emission along the direction of the electric field polarization.\n\nUsing Fermi’s golden rule, the ionization rate is obtained by combining the squared matrix element with the density of states of the free electron. The final expression simplifies significantly when written in atomic units. The rate depends on the strength of the electric field relative to the characteristic atomic electric field, and it decreases rapidly with increasing electron momentum. Although the photon frequency does not appear explicitly in the final expression, it enters implicitly through the momentum of the emitted electron.",
    "num_tokens": 246
  },
  {
    "chunk_id": 5,
    "text": "We now shift focus to light interacting with atoms more generally. In the optical regime, the wavelength of light is much larger than the size of an atom, which allows us to neglect spatial variations of the electric field across the atom. Magnetic field effects are also suppressed by a factor of v over c and can be ignored in this approximation.\n\nThe interaction between an atom and an external electric field can be described by a perturbation Hamiltonian proportional to the electric dipole moment of the atom dotted with the electric field. This motivates the introduction of the dipole operator, which plays a central role in atomic transitions. In this framework, the perturbation Hamiltonian takes a simple and physically transparent form.\n\nFor a harmonic electric field, the transition probability between two atomic states can be computed using time-dependent perturbation theory. The result depends on the matrix element of the dipole operator between the initial and final states and exhibits the familiar resonance structure associated with energy conservation. At this stage, we obtain transition probabilities rather than rates.",
    "num_tokens": 178
  },
  {
    "chunk_id": 6,
    "text": "To obtain transition rates, we must consider the interaction of atoms with a distribution of photons, as occurs in thermal radiation. This leads us naturally to Einstein’s analysis of absorption, stimulated emission, and spontaneous emission. We consider a collection of atoms with two energy levels interacting with radiation at thermal equilibrium.\n\nEinstein’s argument begins by assuming that atomic populations reach equilibrium under the influence of radiation. The populations of the two levels are related by the Boltzmann factor, while the radiation field is described by the blackbody spectrum. By balancing the rates of absorption and emission processes, Einstein showed that absorption and stimulated emission alone are insufficient to achieve equilibrium.\n\nThis observation led to the introduction of spontaneous emission as an additional fundamental process. Spontaneous emission allows an excited atom to decay without requiring the presence of external photons. Incorporating spontaneous emission restores consistency with thermal equilibrium and leads to relations between the coefficients governing absorption, stimulated emission, and spontaneous emission.\n\nFrom this analysis, one finds that the coefficients for absorption and stimulated emission are equal, while the spontaneous emission coefficient is related to them through a universal factor involving the transition frequency. These relations allow spontaneous emission rates to be inferred from stimulated processes, which are often easier to calculate.\n\nThe physical picture that emerges is rich and far-reaching. At low temperatures, spontaneous emission dominates because few photons are present. At higher temperatures, stimulated processes become increasingly important due to the growing photon density. These ideas form the foundation for understanding lasers, where stimulated emission leads to amplification of radiation.\n\nIn a two-level system, stimulated emission occurs when an incoming photon induces an excited atom to decay, emitting an additional photon with the same frequency, phase, and direction. This process underlies the principle of light amplification by stimulated emission of radiation. Achieving laser action requires population inversion, which is typically accomplished using additional energy levels and optical pumping.\n\nFinally, we return to the broader perspective. The study of atom–light interactions using time-dependent perturbation theory provides quantitative predictions for transition probabilities and rates. Through examples such as hydrogen ionization and Einstein’s arguments for radiation balance, we see how microscopic quantum processes connect directly to macroscopic phenomena such as blackbody radiation and laser operation.\n\nThis concludes our discussion of atom–light interactions and sets the stage for more general treatments of electromagnetic interactions in quantum systems.",
    "num_tokens": 394
  },
  {
    "chunk_id": 7,
    "text": "Today we complete our discussion of atoms interacting with light and transition rates induced by thermal radiation, and then move on to a new but closely related subject: charged particles in electromagnetic fields. This marks the conclusion of time-dependent perturbation theory in the course and sets the stage for more general treatments of electromagnetic interactions in quantum mechanics.\n\nWe begin by reviewing transition rates induced by thermal radiation. In earlier lectures, we studied discrete transitions between atomic energy levels driven by a single harmonic perturbation. In thermal radiation, however, the electric field is not a single coherent wave but an incoherent superposition of many electromagnetic modes with different frequencies, amplitudes, and directions.\n\nEach mode of the radiation field can independently contribute to the transition probability. Because these contributions are incoherent, the probabilities must be summed rather than the amplitudes. This sum over discrete modes can be replaced by an integral over frequency, weighted by the energy density of the radiation field as a function of frequency.\n\nThe dominant contribution to the transition probability comes from frequencies close to the atomic transition frequency. As in earlier applications of Fermi’s golden rule, the oscillatory factor sharply selects these resonant frequencies. In the long-time limit, the total transition probability grows linearly with time, allowing the definition of a transition rate.\n\nA subtlety arises because thermal radiation is unpolarized and arrives from all directions. As a result, when evaluating the transition rate, one must average over all possible directions of the electric field polarization. This angular averaging leads to a simple result: the squared dipole matrix element is replaced by one third of its magnitude squared.\n\nCombining these ingredients yields a compact expression for the transition rate induced by thermal radiation. The rate is proportional to the squared magnitude of the dipole matrix element and to the energy density of the radiation field evaluated at the transition frequency. This result closely parallels the structure of Fermi’s golden rule, even though the transition is between discrete atomic states rather than into a continuum.",
    "num_tokens": 338
  },
  {
    "chunk_id": 8,
    "text": "We now complete Einstein’s analysis of absorption, stimulated emission, and spontaneous emission. Using quantum mechanics, we can compute the Einstein B coefficients directly in terms of dipole matrix elements. The spontaneous emission coefficient A is then determined from the B coefficient through Einstein’s relations, involving the cube of the transition frequency.\n\nThe spontaneous emission rate defines the lifetime of an excited atomic state. If an atom can decay through multiple channels, the total decay rate is the sum of the partial decay rates, and the total lifetime is the inverse of this sum. These concepts allow quantitative predictions for atomic lifetimes that can be compared directly with experiment.\n\nAn important remaining ingredient is the evaluation of dipole matrix elements. Selection rules determine when these matrix elements are nonzero. For electric dipole transitions, the change in the magnetic quantum number must be zero or plus or minus one, and the change in the orbital angular momentum quantum number must be plus or minus one. These rules explain the relative stability of certain excited states in hydrogen and determine which radiative transitions are allowed.",
    "num_tokens": 182
  },
  {
    "chunk_id": 9,
    "text": "We now turn to charged particles in electromagnetic fields. In classical electromagnetism, electric and magnetic fields are often regarded as the fundamental physical quantities, while scalar and vector potentials are treated as auxiliary mathematical tools. In quantum mechanics, this viewpoint must be revised.\n\nThe electromagnetic fields can be expressed in terms of a scalar potential and a vector potential. These potentials are not uniquely defined: different choices of potentials related by a gauge transformation give rise to the same electric and magnetic fields. In classical physics, such gauge freedom has no observable consequences.\n\nIn quantum mechanics, however, the potentials play a central role. The Schrödinger equation for a charged particle in electromagnetic fields involves the scalar and vector potentials directly. As a result, gauge transformations must be accompanied by corresponding transformations of the wave function.\n\nGauge invariance in quantum mechanics means that physical predictions are unchanged when the potentials are transformed, provided the wave function is multiplied by an appropriate position- and time-dependent phase factor. Although the wave function itself changes, observable quantities such as expectation values remain the same.\n\nThis perspective reveals that electromagnetic potentials are more fundamental than the fields in quantum theory. In certain situations involving nontrivial topology, different vector potentials can produce the same electric and magnetic fields but are not related by a gauge transformation. These cases correspond to physically distinct electromagnetic configurations and can lead to observable quantum effects.\n\nWe write the Schrödinger equation for a charged particle in electromagnetic fields by replacing the momentum operator with a modified operator that includes the vector potential. This modification ensures consistency with gauge invariance and leads, through Heisenberg’s equations of motion, to the Lorentz force law in the classical limit.",
    "num_tokens": 284
  },
  {
    "chunk_id": 10,
    "text": "This concludes our discussion of transition rates induced by radiation, Einstein coefficients, and the foundations of charged-particle dynamics in electromagnetic fields. These ideas will serve as the basis for further developments involving Landau levels, magnetic fields, and topological effects in quantum mechanics.\n\nWe continue our study of charged particles in electromagnetic fields and examine in detail how gauge invariance is implemented in quantum mechanics. We also explore one of the most important applications of these ideas: the motion of a charged particle in a constant magnetic field and the emergence of Landau levels.\n\nWe begin by revisiting the Schrödinger equation for a charged particle coupled to electromagnetic fields. The standard kinetic energy term is modified by replacing the momentum operator with a combination that includes the vector potential. This replacement ensures that the dynamics are consistent with electromagnetic interactions and introduces new conceptual subtleties.\n\nBecause electromagnetic potentials are not unique, the Schrödinger equation must be invariant under gauge transformations. A gauge transformation changes the scalar and vector potentials while leaving the electric and magnetic fields unchanged. To preserve physical predictions, the wave function must also transform by a position- and time-dependent phase factor.\n\nThis structure leads naturally to the concept of a gauge-covariant derivative. When written in terms of these covariant derivatives, the Schrödinger equation makes its gauge invariance manifest. Operators that appear intuitive in the absence of electromagnetic fields, such as the canonical momentum, are no longer gauge-invariant observables. Instead, physically meaningful quantities involve combinations that include the vector potential.\n\nWe now apply these ideas to the motion of a charged particle in a uniform magnetic field. Classically, such a particle undergoes circular motion with a frequency known as the cyclotron frequency. In quantum mechanics, this problem leads to discrete energy levels known as Landau levels.\n\nTo solve the problem, we choose a convenient gauge for the vector potential. In the Landau gauge, one component of the momentum operator commutes with the Hamiltonian, allowing solutions that are plane waves in one direction and harmonic oscillator states in the perpendicular direction. The resulting Hamiltonian reduces to that of a shifted harmonic oscillator.\n\nThe energy spectrum consists of equally spaced levels separated by the cyclotron frequency. Each Landau level corresponds to a different excitation of the harmonic oscillator. Remarkably, the energy does not depend on the momentum associated with the plane-wave direction, leading to an infinite degeneracy of each Landau level.\n\nThis degeneracy has a clear physical interpretation. By forming superpositions of degenerate states, one can construct wave packets localized in space that correspond more closely to classical circular orbits. The characteristic spatial scale of these states is set by the magnetic length, which depends on the strength of the magnetic field.",
    "num_tokens": 451
  },
  {
    "chunk_id": 11,
    "text": "To better understand the degeneracy, we consider a finite sample with periodic boundary conditions. Quantizing the allowed momenta leads to a finite number of states per Landau level. This number is proportional to the area of the sample and the magnetic field strength.\n\nThe degeneracy of each Landau level is equal to the magnetic flux through the sample divided by a fundamental unit of flux, known as the flux quantum. This result plays a central role in condensed matter physics and underlies phenomena such as the quantum Hall effect.\n\nWe now turn to a deeper aspect of gauge invariance by considering magnetic fields on spaces with nontrivial topology, such as a torus. Although a constant magnetic field satisfies Maxwell’s equations, it does not always correspond to a physically admissible configuration in quantum mechanics.\n\nTo describe a magnetic field on a torus, one must find a vector potential that is well-defined up to gauge transformations. This requirement leads to a quantization condition on the magnetic flux through the torus. Only magnetic fields whose total flux is an integer multiple of the flux quantum are allowed.",
    "num_tokens": 184
  },
  {
    "chunk_id": 12,
    "text": "This example illustrates a profound lesson of quantum mechanics: electromagnetic potentials, rather than fields alone, determine the physical content of a theory. Two configurations with identical electric and magnetic fields may be physically inequivalent if their potentials are not related by a gauge transformation.\n\nThe quantization of magnetic flux and the structure of Landau levels demonstrate how topology, gauge invariance, and quantum mechanics combine to produce observable effects. These ideas will continue to play a crucial role in later topics involving magnetic fields, topological phases, and condensed matter systems.",
    "num_tokens": 89
  }
]